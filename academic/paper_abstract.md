### 摘要写作

 摘要写作指南

摘要
由于在线搜索数据库通常只包含摘要，因此撰写一份完整而简洁的工作描述至关重要，以吸引潜在读者获取全文。本文描述了如何为会议和期刊论文撰写出色的计算机架构摘要。作者应遵循包括动机、问题陈述、方法、结果和结论在内的清单。遵循此清单应增加人们花时间获取并阅读您完整论文的机会。

引言
现在，由于在线出版数据库的使用普遍，撰写一份真正优秀的摘要比十年前更加重要。摘要始终承担着“销售”您的工作的功能。但现在，摘要不仅要说服读者继续阅读附加论文的其余部分，而且必须说服读者离开办公室的舒适环境，去图书馆（或更糟糕的是，通过馆际互借长时间等待后）寻找文章副本。在商业环境中，“执行摘要”通常是唯一被重要人物阅读的报告部分；它应该在内容上（如果不是在语气上）与期刊论文摘要相似。

清单：摘要的组成部分
尽管摘要相当简短，但它必须完成几乎与随后的多页论文相同的工作。在计算机架构论文中，这意味着它在大多数情况下应包括以下部分。每个部分通常是一个句子，尽管有创意的空间。特别是，部分可以合并或分散在一组句子中。以下作为您下一个摘要的清单：

动机：
为什么我们关心这个问题和结果？如果问题不是显然的“有趣”，最好首先提出动机；但如果您的工作是在广泛认为重要的问题上取得的增量进展，那么最好首先提出问题陈述，以表明您正在处理的更大问题的一部分。本节应包括您工作的重要性、领域的难度以及如果成功可能产生的影响。

问题陈述：
您试图解决什么问题？您的工作范围是什么（一种通用方法，还是特定情况）？要小心不要使用太多术语。在某些情况下，将问题陈述放在动机之前是合适的，但这通常只有在大多数读者已经理解问题重要性的情况下才有效。

方法：
您如何解决或取得问题进展？您是否使用了仿真、分析模型、原型构建，还是对实际产品进行了现场数据分析？您的工作范围有多大（您是查看了一个应用程序还是二十种不同编程语言中的一百个程序？）您控制、忽略或测量了哪些重要变量？

结果：
答案是什么？具体来说，大多数优秀的计算机架构论文得出的结论是，某物比另一物快多少百分比、便宜、小或其他方面更好。将结果放在那里，用数字表示。避免模糊的、挥手式的结果，如“非常”、“小”或“显著”。如果您必须模糊，只有在您可以谈论数量级改进时才被允许这样做。这里有一种紧张关系，即您不应提供容易被误解的数字，但另一方面，您没有空间容纳所有警告。

结论：
您的答案意味着什么？它会改变世界（不太可能）、成为一个重要的“胜利”、是一个不错的技巧，还是仅仅作为一个路标指示这条路是浪费时间（所有先前的结果都是有用的）。您的结果是否具有普遍性、潜在的普遍性，还是特定于某个案例？

其他考虑
摘要必须是论文的完全自包含的、胶囊式的描述。它不能假设（或试图激发）读者翻阅以寻找对某些模糊陈述的解释。它必须完全独立地有意义。需要考虑的一些点包括：

满足字数限制。如果您的摘要太长，要么会被拒绝，要么会有人用链锯将其削减到合适的大小。您的目的将更好地通过自己进行艰难的削减工作来实现，而不是留给可能更感兴趣的人，他们可能更关心满足大小限制而不是以最佳方式展示您的努力。通常，摘要的字数限制在150到200字之间。

如果结果有任何重大限制或局限性，应该说明，即使只是使用“可能”、“可以”、“可能”和“似乎”等“逃避性词语”。

想出半打搜索短语和关键词，这些是寻找您工作的人可能会使用的。确保这些确切的短语出现在您的摘要中，以便它们会在搜索结果列表的顶部出现。

通常，论文的背景由其出现的出版物设定（例如，IEEE计算机杂志的文章通常关于计算机技术）。但是，如果您的论文出现在某种非传统的场合，请确保在问题陈述中包含它真正适用的领域或主题区域。

一些出版物要求“关键词”。这些有两个目的。它们用于促进关键词索引搜索，这在现在在线摘要文本搜索常用的情况下已大大减少重要性。然而，它们也用于将论文分配给审稿委员会或编辑，这对您的命运可能极为重要。因此，请确保您选择的关键词使将您的论文分配给审稿类别变得明显（例如，如果有会议主题列表，请将您选择的主题区域作为关键词元组之一）。

结论
撰写高效的摘要是一项艰苦的工作，但通过吸引人们阅读您的出版物，它将为您带来更大的世界影响力。确保您下次撰写的摘要包含所有优秀摘要的组成部分。

---

摘要示例
案例1：
深度神经网络（DNNs）是强大的模型，在困难的学习任务上取得了卓越的性能。尽管DNNs在有大量标记训练集时工作良好，但它们不能用于将序列映射到序列。在本文中，我们提出了一种对序列结构假设最少的通用端到端序列学习方法。我们的方法使用多层长短期记忆（LSTM）将输入序列映射到固定维度的向量，然后另一个深度LSTM从向量解码目标序列。我们的主要结果是，在WMT'14数据集上的英语到法语翻译任务中，LSTM产生的翻译在完整测试集上达到了34.8的BLEU分数，其中LSTM在词汇表外单词上的BLEU分数受到了惩罚。此外，LSTM在长句子上没有困难。相比之下，基于短语的SMT系统在同一数据集上达到了33.3的BLEU分数。当我们使用LSTM对前述SMT系统产生的1000个假设进行重排时，其BLEU分数提高到36.5，接近此任务上先前的最佳结果。LSTM还学习了对词序敏感且相对不变的合理短语和句子表示，这些表示对主动语态和被动语态相对不变。最后，我们发现，将所有源句子中的单词顺序颠倒（但不是目标句子），显著提高了LSTM的性能，因为这样做在源句子和目标句子之间引入了许多短期依赖关系，使优化问题变得更容易。

案例2：
最近的工作通过在大型文本语料库上预训练，然后在特定任务上进行微调，已经在许多自然语言处理（NLP）任务和基准测试中取得了显著进步。虽然这种方法在架构上通常是任务无关的，但它仍然需要数千或数万个示例的任务特定微调数据集。相比之下，人类通常可以从几个示例或简单指令中执行新的语言任务——这是当前NLP系统仍然很难做到的事情。在这里，我们展示了扩大语言模型规模极大地提高了任务无关的、少样本性能，有时甚至达到了与先前的最先进的微调方法相竞争的水平。具体来说，我们训练了一个具有1750亿参数的自回归语言模型GPT-3，比任何以前的非稀疏语言模型多10倍，并在少样本设置中测试其性能。对于所有任务，GPT-3在没有任何梯度更新或微调的情况下应用，任务和少样本演示完全通过与模型的文本交互指定。GPT-3在许多NLP数据集上取得了强大的性能，包括翻译、问答和完形填空任务，以及需要即时推理或领域适应的几项任务，如解乱单词、在句子中使用新单词或执行3位数算术。同时，我们还确定了GPT-3在少样本学习中仍然挣扎的一些数据集，以及GPT-3在大型网络语料库训练中面临的方法论问题。最后，我们发现GPT-3可以生成新闻文章样本，人类评估者很难将其与人类撰写的文章区分开来。我们讨论了这一发现以及GPT-3总体上的更广泛的社会影响。

---

{{论文引言}}

请根据上述论文指南撰写一份专业的摘要。请遵循上述指南撰写，摘要应为一段，与上述示例类似。